<!--
 FileName:      kl_divergence
 Author:        8ucchiman
 CreatedDate:   2023-05-08 17:30:18
 LastModified:  2023-01-25 10:56:12 +0900
 Reference:     https://www.momoyama-usagi.com/entry/info-entropy
 Description:   ---
-->


# klダイバージェンス
`2つの確率分布の違いを数量化したもの`

交差エントロピーと情報エントロピーの差分
$
    D_{KL}(P|Q) = H(P, Q) - H(P)
$

$H(P, Q)=E[-\log{Q}]$
$H(P)=E[-\log(P)]$
交差エントロピー



